{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras import optimizers\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Flatten, MaxPooling2D, AveragePooling2D\n",
        "from keras.callbacks import LearningRateScheduler, TensorBoard"
      ],
      "metadata": {
        "id": "oJ6QqNBiPsNR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test)= cifar10.load_data()"
      ],
      "metadata": {
        "id": "LSkVJaAhQzQg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  model = Sequential()\n",
        "  model.add (Conv2D(6, (5,5), padding ='valid', activation = 'relu',kernel_initializer = 'he_normal', input_shape= (32,32,3)))\n",
        "  model.add(AveragePooling2D((2,2), strides = (2,2)))\n",
        "  model.add (Conv2D(16, (5,5), padding = 'valid', activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "  model.add(AveragePooling2D((2,2), strides = (2,2)))\n",
        "  model.add (Flatten())\n",
        "  model.add (Dense(120, activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "  model.add (Dense (84, activation = 'relu', kernel_initializer = 'he_normal'))\n",
        "  model.add (Dense (10, activation = 'softmax', kernel_initializer = 'he_normal'))\n",
        "  sgd = optimizers.SGD(learning_rate=0.001, momentum = 0.9, nesterov = True)\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
        "  return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hpIR1doJRB0j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch):\n",
        "    if epoch < 100:\n",
        "        return 0.01\n",
        "    if epoch < 150:\n",
        "        return 0.005\n",
        "    return 0.001"
      ],
      "metadata": {
        "id": "Rl-KkN71XpPD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "mean = [125.307, 122.95, 113.865]\n",
        "std = [62.9932, 62.0887, 66.7048]\n",
        "epochs = 200\n",
        "iteration = 391\n",
        "batch_size    = 128\n",
        "y_train = keras.utils.to_categorical (y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical (y_test, num_classes)\n",
        "x_train = x_train.astype ('float32')\n",
        "x_test = x_test.astype ('float32')\n",
        "for i in range(3):\n",
        "    x_train[:,:,:,i] = (x_train[:,:,:,i] - mean[i]) / std[i]\n",
        "    x_test[:,:,:,i] = (x_test[:,:,:,i] - mean[i]) / std[i]\n",
        "model = build_model()\n",
        "print (model.summary())\n",
        "change_lr = LearningRateScheduler(scheduler)\n",
        "tb_cb = TensorBoard(log_dir='./lenet_dp_da', histogram_freq=0)\n",
        "cbks = [change_lr,tb_cb]\n",
        "model.fit (x_train, y_train, batch_size=batch_size, steps_per_epoch = iteration, epochs = epochs, validation_data = (x_test, y_test), callbacks = cbks)\n",
        "model.save_weights ('./lenet_dp_da.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xf7CXKkeVpsJ",
        "outputId": "787f2273-eea3-46a0-ae15-8151cd328b08"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │           \u001b[38;5;34m456\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │         \u001b[38;5;34m2,416\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │        \u001b[38;5;34m48,120\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)             │        \u001b[38;5;34m10,164\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m850\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">456</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,416</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ average_pooling2d_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">48,120</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,164</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">850</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m62,006\u001b[0m (242.21 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,006</span> (242.21 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m62,006\u001b[0m (242.21 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,006</span> (242.21 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Epoch 1/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.2753 - loss: 1.9854 - val_accuracy: 0.4650 - val_loss: 1.4763 - learning_rate: 0.0100\n",
            "Epoch 2/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.4903 - loss: 1.4290 - val_accuracy: 0.5220 - val_loss: 1.3421 - learning_rate: 0.0100\n",
            "Epoch 3/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5448 - loss: 1.2844 - val_accuracy: 0.5598 - val_loss: 1.2383 - learning_rate: 0.0100\n",
            "Epoch 4/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5782 - loss: 1.1881 - val_accuracy: 0.5729 - val_loss: 1.2046 - learning_rate: 0.0100\n",
            "Epoch 5/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6013 - loss: 1.1238 - val_accuracy: 0.5831 - val_loss: 1.1825 - learning_rate: 0.0100\n",
            "Epoch 6/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.6239 - loss: 1.0628 - val_accuracy: 0.6167 - val_loss: 1.1001 - learning_rate: 0.0100\n",
            "Epoch 7/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6452 - loss: 1.0108 - val_accuracy: 0.6191 - val_loss: 1.0822 - learning_rate: 0.0100\n",
            "Epoch 8/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6589 - loss: 0.9706 - val_accuracy: 0.6349 - val_loss: 1.0568 - learning_rate: 0.0100\n",
            "Epoch 9/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6707 - loss: 0.9359 - val_accuracy: 0.6201 - val_loss: 1.1250 - learning_rate: 0.0100\n",
            "Epoch 10/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6836 - loss: 0.8954 - val_accuracy: 0.6450 - val_loss: 1.0309 - learning_rate: 0.0100\n",
            "Epoch 11/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6957 - loss: 0.8671 - val_accuracy: 0.6351 - val_loss: 1.0591 - learning_rate: 0.0100\n",
            "Epoch 12/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.7028 - loss: 0.8414 - val_accuracy: 0.6465 - val_loss: 1.0414 - learning_rate: 0.0100\n",
            "Epoch 13/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7084 - loss: 0.8278 - val_accuracy: 0.6502 - val_loss: 1.0303 - learning_rate: 0.0100\n",
            "Epoch 14/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7177 - loss: 0.7940 - val_accuracy: 0.6480 - val_loss: 1.0501 - learning_rate: 0.0100\n",
            "Epoch 15/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7287 - loss: 0.7681 - val_accuracy: 0.6584 - val_loss: 1.0224 - learning_rate: 0.0100\n",
            "Epoch 16/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7362 - loss: 0.7496 - val_accuracy: 0.6545 - val_loss: 1.0379 - learning_rate: 0.0100\n",
            "Epoch 17/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7464 - loss: 0.7190 - val_accuracy: 0.6428 - val_loss: 1.0797 - learning_rate: 0.0100\n",
            "Epoch 18/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7532 - loss: 0.7018 - val_accuracy: 0.6442 - val_loss: 1.0883 - learning_rate: 0.0100\n",
            "Epoch 19/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7600 - loss: 0.6805 - val_accuracy: 0.6551 - val_loss: 1.0361 - learning_rate: 0.0100\n",
            "Epoch 20/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7705 - loss: 0.6517 - val_accuracy: 0.6411 - val_loss: 1.1262 - learning_rate: 0.0100\n",
            "Epoch 21/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7741 - loss: 0.6394 - val_accuracy: 0.6604 - val_loss: 1.0821 - learning_rate: 0.0100\n",
            "Epoch 22/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7793 - loss: 0.6196 - val_accuracy: 0.6569 - val_loss: 1.0723 - learning_rate: 0.0100\n",
            "Epoch 23/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.7853 - loss: 0.6049 - val_accuracy: 0.6554 - val_loss: 1.1051 - learning_rate: 0.0100\n",
            "Epoch 24/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7962 - loss: 0.5819 - val_accuracy: 0.6413 - val_loss: 1.1315 - learning_rate: 0.0100\n",
            "Epoch 25/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.7967 - loss: 0.5732 - val_accuracy: 0.6498 - val_loss: 1.1577 - learning_rate: 0.0100\n",
            "Epoch 26/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8087 - loss: 0.5453 - val_accuracy: 0.6529 - val_loss: 1.1552 - learning_rate: 0.0100\n",
            "Epoch 27/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8144 - loss: 0.5287 - val_accuracy: 0.6471 - val_loss: 1.1950 - learning_rate: 0.0100\n",
            "Epoch 28/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8166 - loss: 0.5147 - val_accuracy: 0.6503 - val_loss: 1.1929 - learning_rate: 0.0100\n",
            "Epoch 29/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8179 - loss: 0.5097 - val_accuracy: 0.6489 - val_loss: 1.2353 - learning_rate: 0.0100\n",
            "Epoch 30/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8223 - loss: 0.4907 - val_accuracy: 0.6483 - val_loss: 1.2538 - learning_rate: 0.0100\n",
            "Epoch 31/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8315 - loss: 0.4752 - val_accuracy: 0.6454 - val_loss: 1.2687 - learning_rate: 0.0100\n",
            "Epoch 32/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8346 - loss: 0.4644 - val_accuracy: 0.6401 - val_loss: 1.2889 - learning_rate: 0.0100\n",
            "Epoch 33/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8390 - loss: 0.4540 - val_accuracy: 0.6442 - val_loss: 1.3290 - learning_rate: 0.0100\n",
            "Epoch 34/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8482 - loss: 0.4306 - val_accuracy: 0.6358 - val_loss: 1.3523 - learning_rate: 0.0100\n",
            "Epoch 35/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8482 - loss: 0.4255 - val_accuracy: 0.6318 - val_loss: 1.4181 - learning_rate: 0.0100\n",
            "Epoch 36/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8485 - loss: 0.4169 - val_accuracy: 0.6387 - val_loss: 1.4260 - learning_rate: 0.0100\n",
            "Epoch 37/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8570 - loss: 0.4035 - val_accuracy: 0.6367 - val_loss: 1.4525 - learning_rate: 0.0100\n",
            "Epoch 38/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8617 - loss: 0.3848 - val_accuracy: 0.6370 - val_loss: 1.4561 - learning_rate: 0.0100\n",
            "Epoch 39/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8623 - loss: 0.3846 - val_accuracy: 0.6352 - val_loss: 1.5230 - learning_rate: 0.0100\n",
            "Epoch 40/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8685 - loss: 0.3704 - val_accuracy: 0.6381 - val_loss: 1.4920 - learning_rate: 0.0100\n",
            "Epoch 41/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8710 - loss: 0.3571 - val_accuracy: 0.6222 - val_loss: 1.6001 - learning_rate: 0.0100\n",
            "Epoch 42/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8711 - loss: 0.3542 - val_accuracy: 0.6297 - val_loss: 1.6736 - learning_rate: 0.0100\n",
            "Epoch 43/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8747 - loss: 0.3471 - val_accuracy: 0.6306 - val_loss: 1.6173 - learning_rate: 0.0100\n",
            "Epoch 44/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8769 - loss: 0.3393 - val_accuracy: 0.6229 - val_loss: 1.6710 - learning_rate: 0.0100\n",
            "Epoch 45/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8829 - loss: 0.3266 - val_accuracy: 0.6288 - val_loss: 1.6844 - learning_rate: 0.0100\n",
            "Epoch 46/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8828 - loss: 0.3264 - val_accuracy: 0.6152 - val_loss: 1.7494 - learning_rate: 0.0100\n",
            "Epoch 47/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8833 - loss: 0.3237 - val_accuracy: 0.6213 - val_loss: 1.7978 - learning_rate: 0.0100\n",
            "Epoch 48/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8881 - loss: 0.3103 - val_accuracy: 0.6328 - val_loss: 1.7572 - learning_rate: 0.0100\n",
            "Epoch 49/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8940 - loss: 0.2970 - val_accuracy: 0.6204 - val_loss: 1.8427 - learning_rate: 0.0100\n",
            "Epoch 50/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8908 - loss: 0.3031 - val_accuracy: 0.6263 - val_loss: 1.8659 - learning_rate: 0.0100\n",
            "Epoch 51/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8864 - loss: 0.3102 - val_accuracy: 0.6242 - val_loss: 1.8494 - learning_rate: 0.0100\n",
            "Epoch 52/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.8963 - loss: 0.2839 - val_accuracy: 0.6253 - val_loss: 1.9599 - learning_rate: 0.0100\n",
            "Epoch 53/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8944 - loss: 0.2893 - val_accuracy: 0.6170 - val_loss: 1.9976 - learning_rate: 0.0100\n",
            "Epoch 54/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8970 - loss: 0.2850 - val_accuracy: 0.6240 - val_loss: 1.9648 - learning_rate: 0.0100\n",
            "Epoch 55/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.8994 - loss: 0.2776 - val_accuracy: 0.6172 - val_loss: 2.0723 - learning_rate: 0.0100\n",
            "Epoch 56/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8993 - loss: 0.2723 - val_accuracy: 0.6244 - val_loss: 2.0118 - learning_rate: 0.0100\n",
            "Epoch 57/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8981 - loss: 0.2814 - val_accuracy: 0.6199 - val_loss: 2.1112 - learning_rate: 0.0100\n",
            "Epoch 58/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9041 - loss: 0.2682 - val_accuracy: 0.6180 - val_loss: 2.1206 - learning_rate: 0.0100\n",
            "Epoch 59/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9026 - loss: 0.2690 - val_accuracy: 0.6253 - val_loss: 2.1233 - learning_rate: 0.0100\n",
            "Epoch 60/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9080 - loss: 0.2570 - val_accuracy: 0.6267 - val_loss: 2.1933 - learning_rate: 0.0100\n",
            "Epoch 61/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9095 - loss: 0.2465 - val_accuracy: 0.6173 - val_loss: 2.2380 - learning_rate: 0.0100\n",
            "Epoch 62/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9075 - loss: 0.2572 - val_accuracy: 0.6197 - val_loss: 2.2099 - learning_rate: 0.0100\n",
            "Epoch 63/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9102 - loss: 0.2437 - val_accuracy: 0.6178 - val_loss: 2.2517 - learning_rate: 0.0100\n",
            "Epoch 64/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9097 - loss: 0.2469 - val_accuracy: 0.6221 - val_loss: 2.2092 - learning_rate: 0.0100\n",
            "Epoch 65/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9129 - loss: 0.2395 - val_accuracy: 0.6161 - val_loss: 2.2710 - learning_rate: 0.0100\n",
            "Epoch 66/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9136 - loss: 0.2370 - val_accuracy: 0.6135 - val_loss: 2.3324 - learning_rate: 0.0100\n",
            "Epoch 67/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9186 - loss: 0.2315 - val_accuracy: 0.6184 - val_loss: 2.3965 - learning_rate: 0.0100\n",
            "Epoch 68/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9172 - loss: 0.2276 - val_accuracy: 0.6180 - val_loss: 2.3916 - learning_rate: 0.0100\n",
            "Epoch 69/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9192 - loss: 0.2269 - val_accuracy: 0.6101 - val_loss: 2.4477 - learning_rate: 0.0100\n",
            "Epoch 70/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9113 - loss: 0.2473 - val_accuracy: 0.6142 - val_loss: 2.4642 - learning_rate: 0.0100\n",
            "Epoch 71/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9203 - loss: 0.2231 - val_accuracy: 0.6219 - val_loss: 2.5084 - learning_rate: 0.0100\n",
            "Epoch 72/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9200 - loss: 0.2178 - val_accuracy: 0.6114 - val_loss: 2.4996 - learning_rate: 0.0100\n",
            "Epoch 73/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9195 - loss: 0.2269 - val_accuracy: 0.6156 - val_loss: 2.5648 - learning_rate: 0.0100\n",
            "Epoch 74/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9222 - loss: 0.2159 - val_accuracy: 0.6159 - val_loss: 2.5810 - learning_rate: 0.0100\n",
            "Epoch 75/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9216 - loss: 0.2226 - val_accuracy: 0.6224 - val_loss: 2.6173 - learning_rate: 0.0100\n",
            "Epoch 76/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9216 - loss: 0.2175 - val_accuracy: 0.6160 - val_loss: 2.6638 - learning_rate: 0.0100\n",
            "Epoch 77/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9298 - loss: 0.1992 - val_accuracy: 0.6129 - val_loss: 2.7004 - learning_rate: 0.0100\n",
            "Epoch 78/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9230 - loss: 0.2128 - val_accuracy: 0.6119 - val_loss: 2.6766 - learning_rate: 0.0100\n",
            "Epoch 79/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9261 - loss: 0.2119 - val_accuracy: 0.6057 - val_loss: 2.8586 - learning_rate: 0.0100\n",
            "Epoch 80/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9271 - loss: 0.2064 - val_accuracy: 0.6098 - val_loss: 2.8665 - learning_rate: 0.0100\n",
            "Epoch 81/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9269 - loss: 0.2072 - val_accuracy: 0.6182 - val_loss: 2.7321 - learning_rate: 0.0100\n",
            "Epoch 82/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9191 - loss: 0.2289 - val_accuracy: 0.6179 - val_loss: 2.7569 - learning_rate: 0.0100\n",
            "Epoch 83/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9310 - loss: 0.1959 - val_accuracy: 0.5994 - val_loss: 2.8498 - learning_rate: 0.0100\n",
            "Epoch 84/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9227 - loss: 0.2215 - val_accuracy: 0.6126 - val_loss: 2.8499 - learning_rate: 0.0100\n",
            "Epoch 85/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9299 - loss: 0.2008 - val_accuracy: 0.6141 - val_loss: 2.8551 - learning_rate: 0.0100\n",
            "Epoch 86/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9271 - loss: 0.2034 - val_accuracy: 0.6178 - val_loss: 2.8188 - learning_rate: 0.0100\n",
            "Epoch 87/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9342 - loss: 0.1881 - val_accuracy: 0.6110 - val_loss: 2.9514 - learning_rate: 0.0100\n",
            "Epoch 88/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9306 - loss: 0.2000 - val_accuracy: 0.6178 - val_loss: 2.9525 - learning_rate: 0.0100\n",
            "Epoch 89/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9342 - loss: 0.1813 - val_accuracy: 0.6141 - val_loss: 2.9786 - learning_rate: 0.0100\n",
            "Epoch 90/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9316 - loss: 0.1965 - val_accuracy: 0.6110 - val_loss: 2.9447 - learning_rate: 0.0100\n",
            "Epoch 91/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9246 - loss: 0.2157 - val_accuracy: 0.6149 - val_loss: 2.8515 - learning_rate: 0.0100\n",
            "Epoch 92/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9328 - loss: 0.1919 - val_accuracy: 0.6057 - val_loss: 3.0113 - learning_rate: 0.0100\n",
            "Epoch 93/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9317 - loss: 0.1927 - val_accuracy: 0.6118 - val_loss: 3.0600 - learning_rate: 0.0100\n",
            "Epoch 94/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9326 - loss: 0.1910 - val_accuracy: 0.6134 - val_loss: 2.9063 - learning_rate: 0.0100\n",
            "Epoch 95/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9314 - loss: 0.1933 - val_accuracy: 0.6073 - val_loss: 3.1095 - learning_rate: 0.0100\n",
            "Epoch 96/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9320 - loss: 0.1948 - val_accuracy: 0.6137 - val_loss: 2.9969 - learning_rate: 0.0100\n",
            "Epoch 97/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9371 - loss: 0.1802 - val_accuracy: 0.6109 - val_loss: 3.0733 - learning_rate: 0.0100\n",
            "Epoch 98/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9362 - loss: 0.1845 - val_accuracy: 0.6053 - val_loss: 3.0914 - learning_rate: 0.0100\n",
            "Epoch 99/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9375 - loss: 0.1839 - val_accuracy: 0.6073 - val_loss: 3.2901 - learning_rate: 0.0100\n",
            "Epoch 100/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9280 - loss: 0.2037 - val_accuracy: 0.6057 - val_loss: 3.0580 - learning_rate: 0.0100\n",
            "Epoch 101/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9616 - loss: 0.1149 - val_accuracy: 0.6222 - val_loss: 3.3888 - learning_rate: 0.0050\n",
            "Epoch 102/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9928 - loss: 0.0284 - val_accuracy: 0.6238 - val_loss: 3.5048 - learning_rate: 0.0050\n",
            "Epoch 103/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9977 - loss: 0.0153 - val_accuracy: 0.6269 - val_loss: 3.6436 - learning_rate: 0.0050\n",
            "Epoch 104/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9988 - loss: 0.0109 - val_accuracy: 0.6256 - val_loss: 3.7922 - learning_rate: 0.0050\n",
            "Epoch 105/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0076 - val_accuracy: 0.6250 - val_loss: 3.8895 - learning_rate: 0.0050\n",
            "Epoch 106/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0059 - val_accuracy: 0.6285 - val_loss: 3.9973 - learning_rate: 0.0050\n",
            "Epoch 107/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0047 - val_accuracy: 0.6289 - val_loss: 4.0791 - learning_rate: 0.0050\n",
            "Epoch 108/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0041 - val_accuracy: 0.6287 - val_loss: 4.1698 - learning_rate: 0.0050\n",
            "Epoch 109/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0037 - val_accuracy: 0.6262 - val_loss: 4.2257 - learning_rate: 0.0050\n",
            "Epoch 110/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0032 - val_accuracy: 0.6284 - val_loss: 4.2904 - learning_rate: 0.0050\n",
            "Epoch 111/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0028 - val_accuracy: 0.6275 - val_loss: 4.3458 - learning_rate: 0.0050\n",
            "Epoch 112/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.6294 - val_loss: 4.3960 - learning_rate: 0.0050\n",
            "Epoch 113/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.6296 - val_loss: 4.4522 - learning_rate: 0.0050\n",
            "Epoch 114/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9999 - loss: 0.0021 - val_accuracy: 0.6287 - val_loss: 4.5010 - learning_rate: 0.0050\n",
            "Epoch 115/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.6277 - val_loss: 4.5412 - learning_rate: 0.0050\n",
            "Epoch 116/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.6283 - val_loss: 4.5853 - learning_rate: 0.0050\n",
            "Epoch 117/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.6280 - val_loss: 4.6158 - learning_rate: 0.0050\n",
            "Epoch 118/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.6279 - val_loss: 4.6490 - learning_rate: 0.0050\n",
            "Epoch 119/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.6273 - val_loss: 4.6975 - learning_rate: 0.0050\n",
            "Epoch 120/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.6285 - val_loss: 4.7182 - learning_rate: 0.0050\n",
            "Epoch 121/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.6296 - val_loss: 4.7523 - learning_rate: 0.0050\n",
            "Epoch 122/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.6280 - val_loss: 4.7832 - learning_rate: 0.0050\n",
            "Epoch 123/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.6290 - val_loss: 4.8075 - learning_rate: 0.0050\n",
            "Epoch 124/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.6285 - val_loss: 4.8404 - learning_rate: 0.0050\n",
            "Epoch 125/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.6281 - val_loss: 4.8662 - learning_rate: 0.0050\n",
            "Epoch 126/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.6290 - val_loss: 4.8936 - learning_rate: 0.0050\n",
            "Epoch 127/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.6291 - val_loss: 4.9146 - learning_rate: 0.0050\n",
            "Epoch 128/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 9.6470e-04 - val_accuracy: 0.6286 - val_loss: 4.9407 - learning_rate: 0.0050\n",
            "Epoch 129/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.4958e-04 - val_accuracy: 0.6277 - val_loss: 4.9617 - learning_rate: 0.0050\n",
            "Epoch 130/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 9.2891e-04 - val_accuracy: 0.6291 - val_loss: 4.9855 - learning_rate: 0.0050\n",
            "Epoch 131/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.6164e-04 - val_accuracy: 0.6288 - val_loss: 5.0127 - learning_rate: 0.0050\n",
            "Epoch 132/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.3838e-04 - val_accuracy: 0.6293 - val_loss: 5.0227 - learning_rate: 0.0050\n",
            "Epoch 133/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.0893e-04 - val_accuracy: 0.6293 - val_loss: 5.0543 - learning_rate: 0.0050\n",
            "Epoch 134/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 8.0210e-04 - val_accuracy: 0.6290 - val_loss: 5.0669 - learning_rate: 0.0050\n",
            "Epoch 135/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 7.7498e-04 - val_accuracy: 0.6273 - val_loss: 5.0919 - learning_rate: 0.0050\n",
            "Epoch 136/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.3539e-04 - val_accuracy: 0.6291 - val_loss: 5.1116 - learning_rate: 0.0050\n",
            "Epoch 137/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 7.3057e-04 - val_accuracy: 0.6285 - val_loss: 5.1248 - learning_rate: 0.0050\n",
            "Epoch 138/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.9209e-04 - val_accuracy: 0.6273 - val_loss: 5.1476 - learning_rate: 0.0050\n",
            "Epoch 139/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.7275e-04 - val_accuracy: 0.6283 - val_loss: 5.1641 - learning_rate: 0.0050\n",
            "Epoch 140/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 6.7559e-04 - val_accuracy: 0.6280 - val_loss: 5.1865 - learning_rate: 0.0050\n",
            "Epoch 141/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.5428e-04 - val_accuracy: 0.6284 - val_loss: 5.1980 - learning_rate: 0.0050\n",
            "Epoch 142/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.2303e-04 - val_accuracy: 0.6283 - val_loss: 5.2192 - learning_rate: 0.0050\n",
            "Epoch 143/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 6.1642e-04 - val_accuracy: 0.6287 - val_loss: 5.2355 - learning_rate: 0.0050\n",
            "Epoch 144/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.7592e-04 - val_accuracy: 0.6281 - val_loss: 5.2458 - learning_rate: 0.0050\n",
            "Epoch 145/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.8061e-04 - val_accuracy: 0.6286 - val_loss: 5.2660 - learning_rate: 0.0050\n",
            "Epoch 146/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 5.6459e-04 - val_accuracy: 0.6286 - val_loss: 5.2773 - learning_rate: 0.0050\n",
            "Epoch 147/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.5133e-04 - val_accuracy: 0.6291 - val_loss: 5.2932 - learning_rate: 0.0050\n",
            "Epoch 148/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.4865e-04 - val_accuracy: 0.6284 - val_loss: 5.3055 - learning_rate: 0.0050\n",
            "Epoch 149/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.3517e-04 - val_accuracy: 0.6288 - val_loss: 5.3216 - learning_rate: 0.0050\n",
            "Epoch 150/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 5.3715e-04 - val_accuracy: 0.6285 - val_loss: 5.3337 - learning_rate: 0.0050\n",
            "Epoch 151/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.9367e-04 - val_accuracy: 0.6284 - val_loss: 5.3392 - learning_rate: 0.0010\n",
            "Epoch 152/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.8798e-04 - val_accuracy: 0.6285 - val_loss: 5.3419 - learning_rate: 0.0010\n",
            "Epoch 153/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.9250e-04 - val_accuracy: 0.6281 - val_loss: 5.3444 - learning_rate: 0.0010\n",
            "Epoch 154/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.9609e-04 - val_accuracy: 0.6282 - val_loss: 5.3474 - learning_rate: 0.0010\n",
            "Epoch 155/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.9511e-04 - val_accuracy: 0.6281 - val_loss: 5.3512 - learning_rate: 0.0010\n",
            "Epoch 156/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.8565e-04 - val_accuracy: 0.6284 - val_loss: 5.3531 - learning_rate: 0.0010\n",
            "Epoch 157/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.8436e-04 - val_accuracy: 0.6287 - val_loss: 5.3554 - learning_rate: 0.0010\n",
            "Epoch 158/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.9007e-04 - val_accuracy: 0.6282 - val_loss: 5.3583 - learning_rate: 0.0010\n",
            "Epoch 159/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.8757e-04 - val_accuracy: 0.6279 - val_loss: 5.3608 - learning_rate: 0.0010\n",
            "Epoch 160/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.9480e-04 - val_accuracy: 0.6281 - val_loss: 5.3639 - learning_rate: 0.0010\n",
            "Epoch 161/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.7875e-04 - val_accuracy: 0.6281 - val_loss: 5.3665 - learning_rate: 0.0010\n",
            "Epoch 162/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.8621e-04 - val_accuracy: 0.6282 - val_loss: 5.3698 - learning_rate: 0.0010\n",
            "Epoch 163/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.6400e-04 - val_accuracy: 0.6287 - val_loss: 5.3714 - learning_rate: 0.0010\n",
            "Epoch 164/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.9042e-04 - val_accuracy: 0.6280 - val_loss: 5.3730 - learning_rate: 0.0010\n",
            "Epoch 165/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.6236e-04 - val_accuracy: 0.6282 - val_loss: 5.3768 - learning_rate: 0.0010\n",
            "Epoch 166/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.7928e-04 - val_accuracy: 0.6285 - val_loss: 5.3801 - learning_rate: 0.0010\n",
            "Epoch 167/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.7370e-04 - val_accuracy: 0.6288 - val_loss: 5.3826 - learning_rate: 0.0010\n",
            "Epoch 168/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.8055e-04 - val_accuracy: 0.6281 - val_loss: 5.3847 - learning_rate: 0.0010\n",
            "Epoch 169/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.7072e-04 - val_accuracy: 0.6288 - val_loss: 5.3879 - learning_rate: 0.0010\n",
            "Epoch 170/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.6389e-04 - val_accuracy: 0.6281 - val_loss: 5.3886 - learning_rate: 0.0010\n",
            "Epoch 171/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.6258e-04 - val_accuracy: 0.6284 - val_loss: 5.3933 - learning_rate: 0.0010\n",
            "Epoch 172/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.5240e-04 - val_accuracy: 0.6287 - val_loss: 5.3962 - learning_rate: 0.0010\n",
            "Epoch 173/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.5927e-04 - val_accuracy: 0.6286 - val_loss: 5.3979 - learning_rate: 0.0010\n",
            "Epoch 174/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.5835e-04 - val_accuracy: 0.6283 - val_loss: 5.3992 - learning_rate: 0.0010\n",
            "Epoch 175/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.4804e-04 - val_accuracy: 0.6282 - val_loss: 5.4029 - learning_rate: 0.0010\n",
            "Epoch 176/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.5325e-04 - val_accuracy: 0.6281 - val_loss: 5.4043 - learning_rate: 0.0010\n",
            "Epoch 177/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.4800e-04 - val_accuracy: 0.6284 - val_loss: 5.4074 - learning_rate: 0.0010\n",
            "Epoch 178/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.6192e-04 - val_accuracy: 0.6281 - val_loss: 5.4099 - learning_rate: 0.0010\n",
            "Epoch 179/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.4706e-04 - val_accuracy: 0.6280 - val_loss: 5.4124 - learning_rate: 0.0010\n",
            "Epoch 180/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.4341e-04 - val_accuracy: 0.6281 - val_loss: 5.4147 - learning_rate: 0.0010\n",
            "Epoch 181/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.5189e-04 - val_accuracy: 0.6284 - val_loss: 5.4173 - learning_rate: 0.0010\n",
            "Epoch 182/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.4675e-04 - val_accuracy: 0.6284 - val_loss: 5.4202 - learning_rate: 0.0010\n",
            "Epoch 183/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.4367e-04 - val_accuracy: 0.6280 - val_loss: 5.4229 - learning_rate: 0.0010\n",
            "Epoch 184/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.3211e-04 - val_accuracy: 0.6288 - val_loss: 5.4259 - learning_rate: 0.0010\n",
            "Epoch 185/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.4434e-04 - val_accuracy: 0.6283 - val_loss: 5.4278 - learning_rate: 0.0010\n",
            "Epoch 186/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.3643e-04 - val_accuracy: 0.6281 - val_loss: 5.4299 - learning_rate: 0.0010\n",
            "Epoch 187/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.4115e-04 - val_accuracy: 0.6286 - val_loss: 5.4323 - learning_rate: 0.0010\n",
            "Epoch 188/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.3691e-04 - val_accuracy: 0.6281 - val_loss: 5.4330 - learning_rate: 0.0010\n",
            "Epoch 189/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.3047e-04 - val_accuracy: 0.6281 - val_loss: 5.4369 - learning_rate: 0.0010\n",
            "Epoch 190/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.2866e-04 - val_accuracy: 0.6283 - val_loss: 5.4380 - learning_rate: 0.0010\n",
            "Epoch 191/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.4053e-04 - val_accuracy: 0.6283 - val_loss: 5.4415 - learning_rate: 0.0010\n",
            "Epoch 192/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.3074e-04 - val_accuracy: 0.6280 - val_loss: 5.4443 - learning_rate: 0.0010\n",
            "Epoch 193/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.2926e-04 - val_accuracy: 0.6281 - val_loss: 5.4460 - learning_rate: 0.0010\n",
            "Epoch 194/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.2262e-04 - val_accuracy: 0.6286 - val_loss: 5.4489 - learning_rate: 0.0010\n",
            "Epoch 195/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 1.0000 - loss: 4.3582e-04 - val_accuracy: 0.6284 - val_loss: 5.4514 - learning_rate: 0.0010\n",
            "Epoch 196/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.2218e-04 - val_accuracy: 0.6284 - val_loss: 5.4530 - learning_rate: 0.0010\n",
            "Epoch 197/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.2146e-04 - val_accuracy: 0.6282 - val_loss: 5.4549 - learning_rate: 0.0010\n",
            "Epoch 198/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 4.1613e-04 - val_accuracy: 0.6284 - val_loss: 5.4581 - learning_rate: 0.0010\n",
            "Epoch 199/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.1514e-04 - val_accuracy: 0.6282 - val_loss: 5.4603 - learning_rate: 0.0010\n",
            "Epoch 200/200\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.2223e-04 - val_accuracy: 0.6283 - val_loss: 5.4620 - learning_rate: 0.0010\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The filename must end in `.weights.h5`. Received: filepath=./lenet_dp_da.h5",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b1e3fc4996df>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mcbks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mchange_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtb_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'./lenet_dp_da.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(model, filepath, overwrite, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".weights.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0;34m\"The filename must end in `.weights.h5`. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0;34mf\"Received: filepath={filepath}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The filename must end in `.weights.h5`. Received: filepath=./lenet_dp_da.h5"
          ]
        }
      ]
    }
  ]
}